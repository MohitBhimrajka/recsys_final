{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to sys.path to import config\n",
    "# This assumes the notebook is in RECSYS_FINAL/notebooks/\n",
    "project_root = Path.cwd().parent # Should be RECSYS_FINAL\n",
    "src_path = project_root / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "# Import config variables\n",
    "import config\n",
    "\n",
    "# Set some display options for pandas\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Configured Raw Data Path: {config.RAW_DATA_DIR}\")\n",
    "print(f\"All Raw Files Found: {config.check_raw_data_exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets using paths from config\n",
    "try:\n",
    "    assessments_df = pd.read_csv(config.ASSESSMENTS_CSV)\n",
    "    courses_df = pd.read_csv(config.COURSES_CSV)\n",
    "    student_assessment_df = pd.read_csv(config.STUDENT_ASSESSMENT_CSV)\n",
    "    student_info_df = pd.read_csv(config.STUDENT_INFO_CSV)\n",
    "    student_registration_df = pd.read_csv(config.STUDENT_REGISTRATION_CSV)\n",
    "    student_vle_df = pd.read_csv(config.STUDENT_VLE_CSV)\n",
    "    vle_df = pd.read_csv(config.VLE_CSV)\n",
    "    print(\"All CSV files loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    print(\"Please ensure the CSV files are in the data/raw/ directory.\")\n",
    "    # Stop execution or handle appropriately\n",
    "\n",
    "# Store dataframes in a dictionary for easier access\n",
    "dataframes = {\n",
    "    \"assessments\": assessments_df,\n",
    "    \"courses\": courses_df,\n",
    "    \"student_assessment\": student_assessment_df,\n",
    "    \"student_info\": student_info_df,\n",
    "    \"student_registration\": student_registration_df,\n",
    "    \"student_vle\": student_vle_df,\n",
    "    \"vle\": vle_df,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic inspection of each dataframe\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"--- DataFrame: {name} ---\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"Info:\")\n",
    "    df.info()\n",
    "    print(\"\\nHead:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    # Only show describe() for dataframes with numerical columns\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "         print(\"\\nDescribe (Numerical):\")\n",
    "         print(df.describe())\n",
    "    # Describe categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(\"\\nDescribe (Categorical):\")\n",
    "        print(df.describe(include=['object', 'category']))\n",
    "    print(\"-\" * (len(name) + 22))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Analyzing student_info ---\")\n",
    "student_info = dataframes['student_info']\n",
    "\n",
    "# Distributions of categorical features\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "sns.countplot(ax=axes[0, 0], x='gender', data=student_info)\n",
    "axes[0, 0].set_title('Gender Distribution')\n",
    "\n",
    "sns.countplot(ax=axes[0, 1], y='region', data=student_info, order=student_info['region'].value_counts().index)\n",
    "axes[0, 1].set_title('Region Distribution')\n",
    "\n",
    "sns.countplot(ax=axes[1, 0], y='highest_education', data=student_info, order=student_info['highest_education'].value_counts().index)\n",
    "axes[1, 0].set_title('Highest Education Distribution')\n",
    "\n",
    "sns.countplot(ax=axes[1, 1], y='imd_band', data=student_info, order=student_info['imd_band'].value_counts(dropna=False).index) # Show NaNs\n",
    "axes[1, 1].set_title('IMD Band Distribution (incl. NaN)')\n",
    "\n",
    "sns.countplot(ax=axes[2, 0], x='age_band', data=student_info, order=student_info['age_band'].value_counts().index)\n",
    "axes[2, 0].set_title('Age Band Distribution')\n",
    "\n",
    "sns.countplot(ax=axes[2, 1], x='disability', data=student_info)\n",
    "axes[2, 1].set_title('Disability Status Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Explore numerical features\n",
    "print(\"\\nPrevious Attempts Distribution:\")\n",
    "sns.histplot(student_info['num_of_prev_attempts'], bins=range(student_info['num_of_prev_attempts'].max() + 2), kde=False)\n",
    "plt.title('Distribution of Previous Attempts')\n",
    "plt.xlabel('Number of Previous Attempts')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStudied Credits Distribution:\")\n",
    "sns.histplot(student_info['studied_credits'], bins=20, kde=True)\n",
    "plt.title('Distribution of Studied Credits')\n",
    "plt.xlabel('Studied Credits')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Check final result distribution\n",
    "print(\"\\nFinal Result Distribution:\")\n",
    "sns.countplot(y='final_result', data=student_info, order=student_info['final_result'].value_counts().index)\n",
    "plt.title('Final Result Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Analyzing courses ---\")\n",
    "courses = dataframes['courses']\n",
    "\n",
    "print(f\"Number of unique modules: {courses['code_module'].nunique()}\")\n",
    "print(f\"Number of unique presentations: {courses.shape[0]}\") # Each row is a presentation\n",
    "print(\"\\nModules and their number of presentations:\")\n",
    "print(courses['code_module'].value_counts())\n",
    "\n",
    "print(\"\\nDistribution of Module Presentation Lengths:\")\n",
    "sns.histplot(courses['module_presentation_length'], bins=20, kde=False)\n",
    "plt.title('Distribution of Module Presentation Lengths')\n",
    "plt.xlabel('Length (days)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Create presentation_id for later use (might do this again in preprocessing)\n",
    "courses['presentation_id'] = courses['code_module'] + '_' + courses['code_presentation']\n",
    "print(f\"\\nCheck unique presentation IDs: {courses['presentation_id'].nunique()} (should match shape[0])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Analyzing student_registration ---\")\n",
    "student_reg = dataframes['student_registration']\n",
    "\n",
    "# Check for multiple registrations per student per presentation (should be unique ideally)\n",
    "reg_duplicates = student_reg.duplicated(subset=['id_student', 'code_module', 'code_presentation']).sum()\n",
    "print(f\"\\nDuplicate registrations (same student, same presentation): {reg_duplicates}\")\n",
    "\n",
    "# Distribution of registration dates (relative to presentation start, which is 0)\n",
    "print(\"\\nDistribution of Registration Dates:\")\n",
    "sns.histplot(student_reg['date_registration'].dropna(), bins=50, kde=True)\n",
    "plt.title('Distribution of Registration Date (relative to start)')\n",
    "plt.xlabel('Days Relative to Presentation Start')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "# Note: Negative values mean registered before start, positive after.\n",
    "\n",
    "# Distribution of unregistration dates\n",
    "print(\"\\nDistribution of Unregistration Dates:\")\n",
    "sns.histplot(student_reg['date_unregistration'].dropna(), bins=50, kde=True)\n",
    "plt.title('Distribution of Unregistration Date (relative to start)')\n",
    "plt.xlabel('Days Relative to Presentation Start')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPercentage of registrations with an unregistration date: \\\n",
    "{student_reg['date_unregistration'].notnull().mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Analyzing student_vle ---\")\n",
    "student_vle = dataframes['student_vle']\n",
    "\n",
    "print(f\"Total interaction records: {student_vle.shape[0]}\")\n",
    "print(f\"Unique students in VLE logs: {student_vle['id_student'].nunique()}\")\n",
    "print(f\"Unique VLE items interacted with: {student_vle['id_site'].nunique()}\")\n",
    "\n",
    "# Distribution of interaction dates\n",
    "print(\"\\nDistribution of Interaction Dates (relative to start):\")\n",
    "sns.histplot(student_vle['date'], bins=50, kde=False)\n",
    "plt.title('Distribution of Interaction Dates')\n",
    "plt.xlabel('Days Relative to Presentation Start')\n",
    "plt.ylabel('Number of Interactions')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of sum_click\n",
    "# Handle potential outliers by looking at quantiles\n",
    "print(\"\\nDistribution of Clicks per Interaction Record:\")\n",
    "print(student_vle['sum_click'].describe(percentiles=[.25, .5, .75, .9, .95, .99]))\n",
    "# Plotting might be skewed, consider log scale or capping\n",
    "sns.histplot(student_vle['sum_click'], bins=50, log_scale=(False, True)) # Log scale for y-axis\n",
    "plt.title('Distribution of Clicks per Interaction Record (Log Y scale)')\n",
    "plt.xlabel('Number of Clicks (sum_click)')\n",
    "plt.ylabel('Frequency (Log Scale)')\n",
    "plt.show()\n",
    "\n",
    "# Interactions per student (across all their registered courses)\n",
    "interactions_per_student = student_vle.groupby('id_student').size()\n",
    "print(\"\\nInteractions per Student (Summary Stats):\")\n",
    "print(interactions_per_student.describe())\n",
    "sns.histplot(interactions_per_student, bins=50, log_scale=True)\n",
    "plt.title('Distribution of Total Interaction Records per Student (Log Scale)')\n",
    "plt.xlabel('Number of Interaction Records (Log Scale)')\n",
    "plt.ylabel('Number of Students (Log Scale)')\n",
    "plt.show()\n",
    "\n",
    "# Clicks per student\n",
    "clicks_per_student = student_vle.groupby('id_student')['sum_click'].sum()\n",
    "print(\"\\nTotal Clicks per Student (Summary Stats):\")\n",
    "print(clicks_per_student.describe())\n",
    "sns.histplot(clicks_per_student, bins=50, log_scale=True)\n",
    "plt.title('Distribution of Total Clicks per Student (Log Scale)')\n",
    "plt.xlabel('Total Clicks (Log Scale)')\n",
    "plt.ylabel('Number of Students (Log Scale)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Analyzing vle ---\")\n",
    "vle = dataframes['vle']\n",
    "\n",
    "print(f\"Total VLE items defined: {vle.shape[0]}\")\n",
    "print(f\"Unique VLE item IDs (id_site): {vle['id_site'].nunique()}\") # Should match shape[0]\n",
    "\n",
    "# Distribution of activity types\n",
    "print(\"\\nDistribution of VLE Activity Types:\")\n",
    "activity_counts = vle['activity_type'].value_counts()\n",
    "sns.barplot(y=activity_counts.index, x=activity_counts.values)\n",
    "plt.title('Distribution of VLE Activity Types')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Activity Type')\n",
    "plt.show()\n",
    "\n",
    "# Weeks - presence of week_from/week_to\n",
    "print(f\"\\nPercentage of VLE items with 'week_from': {vle['week_from'].notnull().mean()*100:.2f}%\")\n",
    "print(f\"Percentage of VLE items with 'week_to': {vle['week_to'].notnull().mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Analyzing assessments & student_assessment ---\")\n",
    "assessments = dataframes['assessments']\n",
    "student_assessment = dataframes['student_assessment']\n",
    "\n",
    "print(f\"Total assessments defined: {assessments.shape[0]}\")\n",
    "print(f\"Unique assessment IDs: {assessments['id_assessment'].nunique()}\") # Should match shape[0]\n",
    "\n",
    "# Assessment types\n",
    "print(\"\\nDistribution of Assessment Types:\")\n",
    "sns.countplot(y='assessment_type', data=assessments, order=assessments['assessment_type'].value_counts().index)\n",
    "plt.title('Distribution of Assessment Types')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of assessment weights\n",
    "sns.histplot(assessments['weight'], bins=20, kde=False)\n",
    "plt.title('Distribution of Assessment Weights')\n",
    "plt.xlabel('Weight (%)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Explore student scores\n",
    "print(\"\\nDistribution of Student Scores:\")\n",
    "print(student_assessment['score'].describe())\n",
    "sns.histplot(student_assessment['score'].dropna(), bins=20, kde=True)\n",
    "plt.title('Distribution of Student Assessment Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Pass/Fail based on score >= 40 (common threshold)\n",
    "student_assessment['passed'] = student_assessment['score'] >= 40\n",
    "print(\"\\nPass Rate (based on score >= 40):\")\n",
    "print(student_assessment['passed'].value_counts(normalize=True))\n",
    "\n",
    "# Submission relative to deadline\n",
    "assessments_renamed = assessments.rename(columns={'date': 'deadline'})\n",
    "student_assessment_merged = pd.merge(\n",
    "    student_assessment,\n",
    "    assessments_renamed[['id_assessment', 'deadline']],\n",
    "    on='id_assessment',\n",
    "    how='left'\n",
    ")\n",
    "student_assessment_merged['days_early'] = student_assessment_merged['deadline'] - student_assessment_merged['date_submitted']\n",
    "\n",
    "print(\"\\nDistribution of Submission Time Relative to Deadline:\")\n",
    "print(student_assessment_merged['days_early'].describe())\n",
    "sns.histplot(student_assessment_merged['days_early'].dropna(), bins=50)\n",
    "plt.title('Submission Time Relative to Deadline (Positive = Early)')\n",
    "plt.xlabel('Days Early')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Average score per highest education level\n",
    "student_info_subset = student_info[['id_student', 'highest_education']]\n",
    "student_scores_merged = pd.merge(student_assessment, student_info_subset, on='id_student')\n",
    "\n",
    "avg_score_by_edu = student_scores_merged.groupby('highest_education')['score'].mean().sort_values()\n",
    "\n",
    "print(\"\\nAverage Assessment Score by Highest Education:\")\n",
    "print(avg_score_by_edu)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=avg_score_by_edu.values, y=avg_score_by_edu.index)\n",
    "plt.title('Average Assessment Score by Highest Education')\n",
    "plt.xlabel('Average Score')\n",
    "plt.ylabel('Highest Education')\n",
    "plt.show()\n",
    "\n",
    "# Example: Interactions vs Final Result\n",
    "student_interactions = student_vle.groupby(['id_student', 'code_module', 'code_presentation']).size().reset_index(name='total_interactions')\n",
    "student_clicks = student_vle.groupby(['id_student', 'code_module', 'code_presentation'])['sum_click'].sum().reset_index(name='total_clicks')\n",
    "\n",
    "student_activity = pd.merge(student_interactions, student_clicks, on=['id_student', 'code_module', 'code_presentation'])\n",
    "student_activity_results = pd.merge(student_info[['id_student', 'code_module', 'code_presentation', 'final_result']], student_activity, on=['id_student', 'code_module', 'code_presentation'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=student_activity_results, x='final_result', y='total_clicks', showfliers=False, # Hide outliers for clarity\n",
    "            order=['Fail', 'Withdrawn', 'Pass', 'Distinction'])\n",
    "plt.title('Total Clicks vs Final Result (Outliers Hidden)')\n",
    "plt.ylabel('Total Clicks per Student per Presentation')\n",
    "plt.yscale('log') # Log scale often useful for clicks\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=student_activity_results, x='final_result', y='total_interactions', showfliers=False,\n",
    "            order=['Fail', 'Withdrawn', 'Pass', 'Distinction'])\n",
    "plt.title('Total Interaction Records vs Final Result (Outliers Hidden)')\n",
    "plt.ylabel('Total Interaction Records per Student per Presentation')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
